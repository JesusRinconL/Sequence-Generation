{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from subprocess import check_output\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si CUDA está disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU detectada:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA no está disponible. PyTorch está utilizando la CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot \"C:\\\\Users\\\\Jesus\\\\Documents\\\\TFM\\\\PROYECTO4\\\\datasets\\\\DS-manseg-4seq\" --name dualseq-basic-v1 --model pix2pix --direction AtoB --display_id -1 --input_nc 3 --output_nc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_average_losses_from_log(log_path):\n",
    "    \"\"\"Carga y calcula la media de las pérdidas por época desde un archivo de logs.\"\"\"\n",
    "    epoch_losses = {}  # Diccionario {epoch: [lista de pérdidas]}\n",
    "    \n",
    "    with open(log_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # Extraer el número de época\n",
    "            epoch_match = re.search(r\"epoch: (\\d+)\", line)\n",
    "            if not epoch_match:\n",
    "                continue  # Si no hay epoch en la línea, saltar\n",
    "            \n",
    "            epoch = int(epoch_match.group(1))\n",
    "            # Si el epoch aún no tiene registros, inicializar\n",
    "            if epoch not in epoch_losses:\n",
    "                epoch_losses[epoch] = { \n",
    "                    \"G_GAN\": [], \"G_L1\": [], \"D_real\": [], \"D_fake\": [], \"D_t1_real\": [], \"D_t1_fake\": [],\n",
    "                    \"G2_GAN\": [], \"G2_L1\": [], \"D2_real\": [], \"D2_fake\": [], \"D2_t1_real\": [], \"D2_t1_fake\": []\n",
    "                }\n",
    "\n",
    "            # Extraer valores de pérdida (solo si epoch fue encontrado)\n",
    "            for key in epoch_losses[epoch].keys():\n",
    "                match = re.search(rf\"{key}: ([\\d\\.]+)\", line)\n",
    "                if match:\n",
    "                    epoch_losses[epoch][key].append(float(match.group(1)))\n",
    "\n",
    "    # Calcular medias por época\n",
    "    epochs = list(epoch_losses.keys())\n",
    "    avg_losses = {key: [np.mean(epoch_losses[epoch][key]) for epoch in epochs] for key in epoch_losses[epochs[0]].keys()}\n",
    "\n",
    "    return epochs, avg_losses\n",
    "\n",
    "log_path = \"C:\\\\Users\\\\Jesus\\Documents\\\\TFM\\\\PROYECTO4\\\\checkpoints\\\\dualseq-basic-v1\\\\loss_log.txt\"\n",
    "epochs, losses = load_average_losses_from_log(log_path)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Generadores\n",
    "axes[0].plot(epochs, losses[\"G_GAN\"], label=\"G_GAN\")\n",
    "axes[0].plot(epochs, losses[\"G_L1\"], label=\"G_L1\")\n",
    "axes[0].plot(epochs, losses[\"G2_GAN\"], label=\"G2_GAN\")\n",
    "axes[0].plot(epochs, losses[\"G2_L1\"], label=\"G2_L1\")\n",
    "axes[0].set_xlabel(\"Epochs\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Losses\", fontsize=16)\n",
    "axes[0].set_title(\"Generators Losses\", fontsize=18)\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].tick_params(axis='both', labelsize=15)\n",
    "axes[0].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "# Discriminadores\n",
    "axes[1].plot(epochs, losses[\"D_real\"], label=\"D_real\")\n",
    "axes[1].plot(epochs, losses[\"D_fake\"], label=\"D_fake\")\n",
    "axes[1].plot(epochs, losses[\"D2_real\"], label=\"D2_real\")\n",
    "axes[1].plot(epochs, losses[\"D2_fake\"], label=\"D2_fake\")\n",
    "\n",
    "axes[1].plot(epochs, losses[\"D_t1_real\"], label=\"D_t1_real\")\n",
    "axes[1].plot(epochs, losses[\"D_t1_fake\"], label=\"D_t1_fake\")\n",
    "axes[1].plot(epochs, losses[\"D2_t1_real\"], label=\"D2_t1_real\")\n",
    "axes[1].plot(epochs, losses[\"D2_t1_fake\"], label=\"D2_t1_fake\")\n",
    "\n",
    "axes[1].set_xlabel(\"Epochs\", fontsize=16)\n",
    "axes[1].set_ylabel(\"Losses\", fontsize=16)\n",
    "axes[1].set_title(\"Discriminators Losses\", fontsize=18)\n",
    "axes[1].legend(fontsize=14)\n",
    "axes[1].tick_params(axis='both', labelsize=15)\n",
    "axes[1].spines[['top', 'right']].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar la última época\n",
    "epoch_numbers = [int(re.search(r'\\(epoch: (\\d+)', line).group(1)) for line in lines if \"(epoch:\" in line]\n",
    "last_epoch = max(epoch_numbers)\n",
    "\n",
    "# Filtrar líneas de la última época\n",
    "last_epoch_lines = [line for line in lines if f\"(epoch: {last_epoch}\" in line]\n",
    "\n",
    "# Métricas a extraer\n",
    "metric_names = [\"G_GAN\", \"G_L1\", \"D_real\", \"D_fake\", \"D2_real\", \"D2_fake\"]\n",
    "metric_values = {name: [] for name in metric_names}\n",
    "\n",
    "# Extraer valores\n",
    "for line in last_epoch_lines:\n",
    "    for name in metric_names:\n",
    "        match = re.search(fr'{name}: ([\\d\\.]+)', line)\n",
    "        if match:\n",
    "            metric_values[name].append(float(match.group(1)))\n",
    "\n",
    "# Calcular promedios\n",
    "mean_metrics = {name: sum(vals)/len(vals) if vals else 0 for name, vals in metric_values.items()}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(mean_metrics.keys(), mean_metrics.values())\n",
    "plt.title(f\"Epoch {last_epoch} - Metrics Mean\")\n",
    "plt.ylabel(\"Mean value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot \"C:\\\\Users\\\\Jesus\\\\Documents\\\\TFM\\\\PROYECTO2\\\\datasets\\\\top_left\" --direction AtoB --model pix2pix --name dualseq-bt_rg-v1 --results_dir ./results/dualseq-CSIC-top_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test_recur.py --dataroot \"C:\\\\Users\\\\Jesus\\\\Documents\\\\TFM\\\\PROYECTO4\\\\datasets\\\\tl_330\" --direction AtoB --model pix2pix --name dualseq-bt_rg-v1 --results_dir ./results/dualseq-CSIC430 --num_recursive_steps 430"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
